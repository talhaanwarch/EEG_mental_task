{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Feature Selection Approach 3",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/talhaanwarch/ConvNet-for-EEG-cognitive-task-classification/blob/master/Feature_Selection_Approach_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nAZkeuKAh84E",
        "colab_type": "text"
      },
      "source": [
        "# Install Packages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZTedeQ8kjcX",
        "colab_type": "text"
      },
      "source": [
        "In this approach data is segmented and feature are calculated for each segment. Then these features are averaged"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2dWHVU6--Do",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9bXPLMDCobm",
        "colab_type": "code",
        "outputId": "c4409296-e3a4-46be-fc1a-29dbb719a7b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install wfdb\n",
        "!pip install mne\n",
        "!pip install nitime"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wfdb\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b2/96/c2200539fdf4f087e14d30ed62a66544b6f441196bcb8ecc7a29ec6503b9/wfdb-2.2.1.tar.gz (94kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 7.7MB/s \n",
            "\u001b[?25hCollecting nose>=1.3.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/15/d8/dd071918c040f50fa1cf80da16423af51ff8ce4a0f2399b7bf8de45ac3d9/nose-1.3.7-py3-none-any.whl (154kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 36.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from wfdb) (1.17.3)\n",
            "Requirement already satisfied: matplotlib>=1.5.1 in /usr/local/lib/python3.6/dist-packages (from wfdb) (3.1.1)\n",
            "Requirement already satisfied: requests>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from wfdb) (2.21.0)\n",
            "Requirement already satisfied: pandas>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from wfdb) (0.25.3)\n",
            "Requirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python3.6/dist-packages (from wfdb) (1.3.1)\n",
            "Requirement already satisfied: sklearn>=0.0 in /usr/local/lib/python3.6/dist-packages (from wfdb) (0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.5.1->wfdb) (2.6.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.5.1->wfdb) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.5.1->wfdb) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.5.1->wfdb) (2.4.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.10.0->wfdb) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.10.0->wfdb) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.10.0->wfdb) (2019.9.11)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.10.0->wfdb) (2.8)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.19.1->wfdb) (2018.9)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn>=0.0->wfdb) (0.21.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib>=1.5.1->wfdb) (1.12.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib>=1.5.1->wfdb) (41.4.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn>=0.0->wfdb) (0.14.0)\n",
            "Building wheels for collected packages: wfdb\n",
            "  Building wheel for wfdb (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wfdb: filename=wfdb-2.2.1-cp36-none-any.whl size=100368 sha256=1d4b4c331f3a015975ae34543c622925bc9f5848624ddc562efa18f65d14d186\n",
            "  Stored in directory: /root/.cache/pip/wheels/bb/a9/00/0078d26b0c15b31be0001af8eb659496709c361c69641303f1\n",
            "Successfully built wfdb\n",
            "Installing collected packages: nose, wfdb\n",
            "Successfully installed nose-1.3.7 wfdb-2.2.1\n",
            "Collecting mne\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/16/18/42a64bf66ec7b690d40fc63231bc3b323307ebd69b253137dd91b8ef7fb6/mne-0.19.1-py3-none-any.whl (6.4MB)\n",
            "\u001b[K     |████████████████████████████████| 6.4MB 7.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from mne) (1.17.3)\n",
            "Requirement already satisfied: scipy>=0.17.1 in /usr/local/lib/python3.6/dist-packages (from mne) (1.3.1)\n",
            "Installing collected packages: mne\n",
            "Successfully installed mne-0.19.1\n",
            "Collecting nitime\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2e/28/3cb014175d93fd01f2b13250afcace3c19e5abfe36790943f3cc6519a8e2/nitime-0.8.1.tar.gz (9.0MB)\n",
            "\u001b[K     |████████████████████████████████| 9.1MB 7.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from nitime) (1.17.3)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (from nitime) (0.29.14)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from nitime) (1.3.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from nitime) (3.1.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from nitime) (2.4)\n",
            "Requirement already satisfied: nibabel in /usr/local/lib/python3.6/dist-packages (from nitime) (2.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->nitime) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->nitime) (2.6.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->nitime) (1.1.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->nitime) (2.4.4)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->nitime) (4.4.1)\n",
            "Requirement already satisfied: bz2file in /usr/local/lib/python3.6/dist-packages (from nibabel->nitime) (0.98)\n",
            "Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.6/dist-packages (from nibabel->nitime) (1.12.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib->nitime) (41.4.0)\n",
            "Building wheels for collected packages: nitime\n",
            "  Building wheel for nitime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nitime: filename=nitime-0.8.1-cp36-cp36m-linux_x86_64.whl size=4038232 sha256=f20a5d6e4efa935d65c403c01c428189eaf9fcfd822fd6457aa5646b6e9620a9\n",
            "  Stored in directory: /root/.cache/pip/wheels/74/02/c5/677c895b41dcaf4fd7c4ff436fbdf8a5d846ed90a0a3276073\n",
            "Successfully built nitime\n",
            "Installing collected packages: nitime\n",
            "Successfully installed nitime-0.8.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wN2iOjELEkWh",
        "colab_type": "code",
        "outputId": "7cde40ef-bfe5-46a8-e3c9-69954395208a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        }
      },
      "source": [
        "!pip install git+https://github.com/forrestbao/pyeeg.git\n",
        "!pip install git+https://github.com/raphaelvallat/entropy.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/forrestbao/pyeeg.git\n",
            "  Cloning https://github.com/forrestbao/pyeeg.git to /tmp/pip-req-build-1l6yhg0f\n",
            "  Running command git clone -q https://github.com/forrestbao/pyeeg.git /tmp/pip-req-build-1l6yhg0f\n",
            "Requirement already satisfied: numpy>=1.9.2 in /usr/local/lib/python3.6/dist-packages (from pyeeg==0.4.4) (1.17.3)\n",
            "Building wheels for collected packages: pyeeg\n",
            "  Building wheel for pyeeg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyeeg: filename=pyeeg-0.4.4-py2.py3-none-any.whl size=28121 sha256=4c4f4ae0bdd9ad906d64785fcef962fb2faee4ba0466bdda438a40b7a5f4bee1\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-pkaqdx6u/wheels/2d/3f/ad/106d4fc80b61d1ea1fc18e76e7439fd98aa043d83d58eae741\n",
            "Successfully built pyeeg\n",
            "Installing collected packages: pyeeg\n",
            "Successfully installed pyeeg-0.4.4\n",
            "Collecting git+https://github.com/raphaelvallat/entropy.git\n",
            "  Cloning https://github.com/raphaelvallat/entropy.git to /tmp/pip-req-build-hr9prixz\n",
            "  Running command git clone -q https://github.com/raphaelvallat/entropy.git /tmp/pip-req-build-hr9prixz\n",
            "Building wheels for collected packages: entropy\n",
            "  Building wheel for entropy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for entropy: filename=entropy-0.1.0-cp36-none-any.whl size=14098 sha256=9093a0b1d15320ad149de546d5b31a0c8922fadfdea096c89dbcecdc96808b61\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-0leh0j0y/wheels/60/ed/d3/b715e38438f1f39edb1383aea79c578073953b25fa576fc71e\n",
            "Successfully built entropy\n",
            "Installing collected packages: entropy\n",
            "Successfully installed entropy-0.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M49QbDhkDHIT",
        "colab_type": "text"
      },
      "source": [
        "# Download data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJiEQY2LCZ4f",
        "colab_type": "code",
        "outputId": "e95d6192-6e34-4345-df73-0da163595495",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "import wfdb\n",
        "dbs = wfdb.get_dbs()\n",
        "wfdb.dl_database('eegmat','data')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Created local base download directory: data\n",
            "Downloading files...\n",
            "Finished downloading files\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rCn0gh3kDMOI",
        "colab_type": "text"
      },
      "source": [
        "# Read data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CfgtZg96ER8W",
        "colab_type": "code",
        "outputId": "2f3e75db-0eb7-4cc0-da8b-6be8965a183d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "import glob\n",
        "import os\n",
        "import mne\n",
        "import re\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MaxAbsScaler"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numba/decorators.py:146: RuntimeWarning: Caching is not available when the 'parallel' target is in use. Caching is now being disabled to allow execution to continue.\n",
            "  warnings.warn(msg, RuntimeWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UbzJ_FPvC1D_",
        "colab_type": "code",
        "outputId": "b1d53e0c-a2e1-4b24-9b9a-feb93906e0c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "path = r'data/' # use your path\n",
        "all_files = glob.glob(os.path.join(path, \"*.edf\")) \n",
        "\n",
        "i=0\n",
        "j=0\n",
        "subject_1=[]\n",
        "subject_2=[]\n",
        "\n",
        "for filename in (all_files):\n",
        "    if int(re.findall(r'\\d+',filename)[1])==1:\n",
        "        data=mne.io.read_raw_edf(filename,preload=True).get_data()[0:-3,10000:40000].T\n",
        "        subject_1.append(data)\n",
        "    else:\n",
        "        data=mne.io.read_raw_edf(filename,preload=True).get_data()[0:-3,0:30000].T\n",
        "        subject_2.append(data)        "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting EDF parameters from /content/data/Subject35_1.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 90999  =      0.000 ...   181.998 secs...\n",
            "Extracting EDF parameters from /content/data/Subject11_2.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n",
            "Extracting EDF parameters from /content/data/Subject20_1.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 90999  =      0.000 ...   181.998 secs...\n",
            "Extracting EDF parameters from /content/data/Subject06_1.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 90999  =      0.000 ...   181.998 secs...\n",
            "Extracting EDF parameters from /content/data/Subject28_1.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 90999  =      0.000 ...   181.998 secs...\n",
            "Extracting EDF parameters from /content/data/Subject18_1.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 90999  =      0.000 ...   181.998 secs...\n",
            "Extracting EDF parameters from /content/data/Subject23_1.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 90999  =      0.000 ...   181.998 secs...\n",
            "Extracting EDF parameters from /content/data/Subject14_1.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 90999  =      0.000 ...   181.998 secs...\n",
            "Extracting EDF parameters from /content/data/Subject27_2.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n",
            "Extracting EDF parameters from /content/data/Subject35_2.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n",
            "Extracting EDF parameters from /content/data/Subject04_2.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n",
            "Extracting EDF parameters from /content/data/Subject02_1.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 90999  =      0.000 ...   181.998 secs...\n",
            "Extracting EDF parameters from /content/data/Subject07_2.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n",
            "Extracting EDF parameters from /content/data/Subject09_2.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n",
            "Extracting EDF parameters from /content/data/Subject28_2.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n",
            "Extracting EDF parameters from /content/data/Subject01_1.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 90999  =      0.000 ...   181.998 secs...\n",
            "Extracting EDF parameters from /content/data/Subject03_2.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n",
            "Extracting EDF parameters from /content/data/Subject29_1.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 90999  =      0.000 ...   181.998 secs...\n",
            "Extracting EDF parameters from /content/data/Subject13_2.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n",
            "Extracting EDF parameters from /content/data/Subject29_2.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n",
            "Extracting EDF parameters from /content/data/Subject10_1.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 93999  =      0.000 ...   187.998 secs...\n",
            "Extracting EDF parameters from /content/data/Subject26_2.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n",
            "Extracting EDF parameters from /content/data/Subject24_2.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n",
            "Extracting EDF parameters from /content/data/Subject31_2.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n",
            "Extracting EDF parameters from /content/data/Subject10_2.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n",
            "Extracting EDF parameters from /content/data/Subject09_1.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 90999  =      0.000 ...   181.998 secs...\n",
            "Extracting EDF parameters from /content/data/Subject25_2.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n",
            "Extracting EDF parameters from /content/data/Subject34_1.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 90999  =      0.000 ...   181.998 secs...\n",
            "Extracting EDF parameters from /content/data/Subject24_1.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 90999  =      0.000 ...   181.998 secs...\n",
            "Extracting EDF parameters from /content/data/Subject23_2.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n",
            "Extracting EDF parameters from /content/data/Subject19_2.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n",
            "Extracting EDF parameters from /content/data/Subject00_2.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n",
            "Extracting EDF parameters from /content/data/Subject03_1.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 90999  =      0.000 ...   181.998 secs...\n",
            "Extracting EDF parameters from /content/data/Subject22_1.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 90999  =      0.000 ...   181.998 secs...\n",
            "Extracting EDF parameters from /content/data/Subject15_2.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n",
            "Extracting EDF parameters from /content/data/Subject31_1.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 39999  =      0.000 ...    79.998 secs...\n",
            "Extracting EDF parameters from /content/data/Subject26_1.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 90999  =      0.000 ...   181.998 secs...\n",
            "Extracting EDF parameters from /content/data/Subject27_1.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 90999  =      0.000 ...   181.998 secs...\n",
            "Extracting EDF parameters from /content/data/Subject32_1.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 90999  =      0.000 ...   181.998 secs...\n",
            "Extracting EDF parameters from /content/data/Subject19_1.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 90999  =      0.000 ...   181.998 secs...\n",
            "Extracting EDF parameters from /content/data/Subject21_2.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n",
            "Extracting EDF parameters from /content/data/Subject04_1.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 84999  =      0.000 ...   169.998 secs...\n",
            "Extracting EDF parameters from /content/data/Subject25_1.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 90999  =      0.000 ...   181.998 secs...\n",
            "Extracting EDF parameters from /content/data/Subject11_1.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 90999  =      0.000 ...   181.998 secs...\n",
            "Extracting EDF parameters from /content/data/Subject34_2.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n",
            "Extracting EDF parameters from /content/data/Subject30_1.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 90999  =      0.000 ...   181.998 secs...\n",
            "Extracting EDF parameters from /content/data/Subject33_2.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n",
            "Extracting EDF parameters from /content/data/Subject14_2.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n",
            "Extracting EDF parameters from /content/data/Subject17_2.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n",
            "Extracting EDF parameters from /content/data/Subject06_2.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n",
            "Extracting EDF parameters from /content/data/Subject12_1.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 90999  =      0.000 ...   181.998 secs...\n",
            "Extracting EDF parameters from /content/data/Subject33_1.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 90999  =      0.000 ...   181.998 secs...\n",
            "Extracting EDF parameters from /content/data/Subject05_2.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n",
            "Extracting EDF parameters from /content/data/Subject15_1.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 90999  =      0.000 ...   181.998 secs...\n",
            "Extracting EDF parameters from /content/data/Subject30_2.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n",
            "Extracting EDF parameters from /content/data/Subject01_2.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n",
            "Extracting EDF parameters from /content/data/Subject12_2.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n",
            "Extracting EDF parameters from /content/data/Subject17_1.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 90999  =      0.000 ...   181.998 secs...\n",
            "Extracting EDF parameters from /content/data/Subject08_2.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n",
            "Extracting EDF parameters from /content/data/Subject20_2.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n",
            "Extracting EDF parameters from /content/data/Subject16_2.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n",
            "Extracting EDF parameters from /content/data/Subject00_1.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 90999  =      0.000 ...   181.998 secs...\n",
            "Extracting EDF parameters from /content/data/Subject22_2.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n",
            "Extracting EDF parameters from /content/data/Subject07_1.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 90999  =      0.000 ...   181.998 secs...\n",
            "Extracting EDF parameters from /content/data/Subject21_1.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 90999  =      0.000 ...   181.998 secs...\n",
            "Extracting EDF parameters from /content/data/Subject13_1.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 90999  =      0.000 ...   181.998 secs...\n",
            "Extracting EDF parameters from /content/data/Subject18_2.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n",
            "Extracting EDF parameters from /content/data/Subject05_1.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 90999  =      0.000 ...   181.998 secs...\n",
            "Extracting EDF parameters from /content/data/Subject02_2.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n",
            "Extracting EDF parameters from /content/data/Subject08_1.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 90999  =      0.000 ...   181.998 secs...\n",
            "Extracting EDF parameters from /content/data/Subject32_2.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n",
            "Extracting EDF parameters from /content/data/Subject16_1.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 90999  =      0.000 ...   181.998 secs...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVH5rTmQDPZ4",
        "colab_type": "text"
      },
      "source": [
        "# Feature Extraction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vHod_4gETis",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from scipy import stats\n",
        "import pyeeg\n",
        "from entropy import *\n",
        "import pywt\n",
        "from nitime import algorithms as alg\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LacFqUQwFbZg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mean(data):\n",
        "    return np.mean(data,axis=0)\n",
        "    \n",
        "def std(data):\n",
        "    return np.std(data,axis=0)\n",
        "\n",
        "def ptp(data):\n",
        "    return np.ptp(data,axis=0)\n",
        "\n",
        "def var(data):\n",
        "        return np.var(data,axis=0)\n",
        "\n",
        "def skewness(data):\n",
        "    return stats.skew(data,axis=0)\n",
        "\n",
        "def kurtosis(data):\n",
        "    return stats.kurtosis(data,axis=0)\n",
        "\n",
        "def app_epy(data):\n",
        "    result=[]\n",
        "    for i in data.T:\n",
        "        result.append(app_entropy(i, order=2, metric='chebyshev'))\n",
        "    return np.array(result)\n",
        "\n",
        "def perm_epy(data):\n",
        "    result=[]\n",
        "    for i in data.T:\n",
        "        result.append(perm_entropy(i, order=3, normalize=True))\n",
        "    return np.array(result)\n",
        "\n",
        "def svd_epy(data):\n",
        "    result=[]\n",
        "    for i in data.T:\n",
        "        result.append(svd_entropy(i, order=3, delay=1, normalize=True))\n",
        "    return np.array(result)\n",
        "\n",
        "def spectral_epy(data):\n",
        "    result=[]\n",
        "    for i in data.T:\n",
        "        result.append(spectral_entropy(i, 100, method='welch', normalize=True))\n",
        "    return np.array(result)\n",
        "\n",
        "def sample_epy(data):\n",
        "    result=[]\n",
        "    for i in data.T:\n",
        "        result.append(sample_entropy(i, order=2, metric='chebyshev'))\n",
        "    return np.array(result)\n",
        "\n",
        "\n",
        "def katz(data):\n",
        "    result=[]\n",
        "    for i in data.T:\n",
        "        result.append(katz_fd(i))\n",
        "    return np.array(result)\n",
        "\n",
        "def higuchi(data):\n",
        "    result=[]\n",
        "    for i in data.T:\n",
        "        result.append(higuchi_fd(i))\n",
        "    return np.array(result)\n",
        "\n",
        "\n",
        "def petrosian(data):\n",
        "    result=[]\n",
        "    for i in data.T:\n",
        "        result.append(petrosian_fd(i))\n",
        "    return np.array(result)\n",
        "\n",
        "def autogressiveModelParameters(data):\n",
        "    feature = []\n",
        "    for i in data.T:\n",
        "        coeff, sig = alg.AR_est_YW(i, order=5)\n",
        "        feature.append(np.mean(coeff))\n",
        "    return np.array(feature)\n",
        "\n",
        "def teager(x):\n",
        "    for i in range(len(x)-1):\n",
        "        return x[i]**2 - (x[i-1]*x[i+1])\n",
        "\n",
        "def wavelet_features(data):\n",
        "    dwt={}\n",
        "    for i in range(18):\n",
        "        dwt[i]=pywt.wavedec(data.T[i],\"db1\", level=4)\n",
        "    mean=[]\n",
        "    tkeo=[]\n",
        "    for i in dwt.values():\n",
        "        for j in range(5):\n",
        "            mean.append(i[j].mean())\n",
        "            tkeo.append(teager(i[j]))\n",
        "    return np.array(tkeo),np.array(mean)\n",
        "\n",
        "def dwt_mean(data):\n",
        "    _,mean= wavelet_features(data)\n",
        "    return mean\n",
        "    \n",
        "def dwt_tkeo(data):\n",
        "    tkeo,_= wavelet_features(data) \n",
        "    return tkeo\n",
        "        \n",
        "\n",
        "def concatenate(data):\n",
        "    return np.concatenate((mean(data),std(data),ptp(data),var(data),skewness(data),kurtosis(data),\n",
        "                           app_epy(data),perm_epy(data),svd_epy(data),spectral_epy(data),sample_epy(data),\n",
        "                           katz(data),higuchi(data),petrosian(data),autogressiveModelParameters(data),dwt_mean(data),\n",
        "                           dwt_tkeo(data)),axis=0)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9MeexQ8ETpq-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3d-KKNdbzwIu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features1=[]\n",
        "for f in subject_1:\n",
        "    feature=[]\n",
        "    b=f.reshape(-1,3000,18)\n",
        "    for i in b:\n",
        "        feature.append(concatenate(i))\n",
        "    features1.append((np.array(feature)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1JktvuFY2vtQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features2=[]\n",
        "for f in subject_2:\n",
        "    feature=[]\n",
        "    b=f.reshape(-1,3000,18)\n",
        "    for i in b:\n",
        "        feature.append(concatenate(i))\n",
        "    features2.append((np.array(feature)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIaQEr_admXE",
        "colab_type": "code",
        "outputId": "9a1ce6dd-e4cd-4b80-a7d5-5fc50a878e26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(features1),len(features2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(36, 36)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3ALH2S1YcSP",
        "colab_type": "code",
        "outputId": "3ac90c12-ef48-432d-89ae-4d8577aaf24f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "features1[0].shape,features1[1].shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((10, 450), (10, 450))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FNFG_XEEfdq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x1=np.array(features1)        \n",
        "x2=np.array(features2)      \n",
        "\n",
        "X=np.concatenate((x1,x2),axis=0)\n",
        "\n",
        "y=np.concatenate(((np.zeros(x1.shape[0])),(np.ones(x2.shape[0]))))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pooCjG-fdtWS",
        "colab_type": "code",
        "outputId": "45a03234-b96f-4dce-8e0b-fb0f5797e710",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X.shape,y.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((72, 10, 450), (72,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qH6vWOzfDUGK",
        "colab_type": "text"
      },
      "source": [
        "# Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIcp2hPcgFdc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np \n",
        "from sklearn.model_selection import ShuffleSplit # or StratifiedShuffleSplit\n",
        "sss = ShuffleSplit(n_splits=1, test_size=0.2)\n",
        "sss.get_n_splits(X, y)\n",
        "train_index, test_index = next(sss.split(X, y)) \n",
        "\n",
        "X_train, X_test = X[train_index], X[test_index] \n",
        "y_train, y_test = y[train_index], y[test_index]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6uog1DejgQqD",
        "colab_type": "code",
        "outputId": "5220d08f-1d47-4aec-8b17-b11671957884",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train.shape,X_test.shape,y_train.shape,y_test.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((57, 10, 450), (15, 10, 450), (57,), (15,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFv7fDZEgkhg",
        "colab_type": "code",
        "outputId": "ed2e07dd-4cba-422b-e65b-971b06f3545a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_test"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imagUIHxgW_r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train = np.array( [ele for ele in y_train for i in range(10)] )\n",
        "y_test =np.array([ele for ele in y_test for i in range(10)] )  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VvhLMvsohz2B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train=X_train.reshape(-1,450)\n",
        "X_test=X_test.reshape(-1,450)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSnrMW1ba9dG",
        "colab_type": "code",
        "outputId": "15212b27-a505-4a5b-f8a8-577690ecc317",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train.shape,X_test.shape,y_train.shape,y_test.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((570, 450), (150, 450), (570,), (150,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVSRKVsvl9Xm",
        "colab_type": "code",
        "outputId": "642e378f-f698-46b7-94f8-d0a3ca80846d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "clf=KNeighborsClassifier(3)\n",
        "clf.fit(X_train,y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "from sklearn.metrics import classification_report,accuracy_score\n",
        "print(classification_report(y_test,y_pred))\n",
        "print('accuracy is ',accuracy_score(y_test, y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.49      0.70      0.58        60\n",
            "         1.0       0.72      0.52      0.61        90\n",
            "\n",
            "    accuracy                           0.59       150\n",
            "   macro avg       0.61      0.61      0.59       150\n",
            "weighted avg       0.63      0.59      0.60       150\n",
            "\n",
            "accuracy is  0.5933333333333334\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F43mLml3DaEE",
        "colab_type": "text"
      },
      "source": [
        "# Cross Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPu2-pvOEE1G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score, log_loss\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import pandas as pd\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqMYWYTSD5De",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classifiers = [\n",
        "    KNeighborsClassifier(3),\n",
        "    SVC(kernel=\"rbf\"),\n",
        "    NuSVC(),\n",
        "    DecisionTreeClassifier(),\n",
        "    RandomForestClassifier(),\n",
        "    AdaBoostClassifier(),\n",
        "    GradientBoostingClassifier(),\n",
        "    GaussianNB(),\n",
        "    LinearDiscriminantAnalysis(),\n",
        "    QuadraticDiscriminantAnalysis(),\n",
        "    LogisticRegression()]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCZ0VGzgiEZE",
        "colab_type": "code",
        "outputId": "09f5ae5d-12ca-4f71-f3fc-57facd00d207",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "\n",
        "skf = StratifiedKFold(n_splits=5)\n",
        "skf.get_n_splits(X, y)\n",
        "\n",
        "acc=[]\n",
        "for train_index, test_index in skf.split(X, y):\n",
        "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    X_train=X_train.reshape(-1,450)\n",
        "    X_test=X_test.reshape(-1,450)\n",
        "\n",
        "    y_train = np.array( [ele for ele in y_train for i in range(10)] )\n",
        "    y_test =np.array([ele for ele in y_test for i in range(10)] )  \n",
        "\n",
        "\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X_train=scaler.fit_transform(X_train)\n",
        "    X_test=scaler.transform(X_test)\n",
        "    \n",
        "    \n",
        "    clf = SVC(kernel=\"rbf\")\n",
        "    clf.fit(X_train,y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    accuracy=accuracy_score(y_test, y_pred)\n",
        "    print(accuracy)\n",
        "    acc.append(accuracy)\n",
        "    \n",
        "print('-------------------------')    \n",
        "print('mean',np.array(acc).mean())    \n",
        "print('std',np.array(acc).std())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.49375\n",
            "0.6142857142857143\n",
            "0.5357142857142857\n",
            "0.65\n",
            "0.5857142857142857\n",
            "-------------------------\n",
            "mean 0.5758928571428571\n",
            "std 0.0555411687721048\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQqS9NjUD3Kc",
        "colab_type": "code",
        "outputId": "753187c7-4b24-4d43-f459-ff5071b363cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 739
        }
      },
      "source": [
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "raw_acc=[]\n",
        "skf = StratifiedKFold(n_splits=5)\n",
        "skf.get_n_splits(X, y)\n",
        "for clf in classifiers:\n",
        "    name = clf.__class__.__name__\n",
        "    clf_acc=[]\n",
        "\n",
        "    print(\"=\"*30)\n",
        "    print(name)       \n",
        "    for train_index, test_index in skf.split(X, y):\n",
        "        X_train, X_test = X[train_index], X[test_index]\n",
        "        y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "        X_train=X_train.reshape(-1,450)\n",
        "        X_test=X_test.reshape(-1,450)\n",
        "\n",
        "        y_train = np.array( [ele for ele in y_train for i in range(10)] )\n",
        "        y_test =np.array([ele for ele in y_test for i in range(10)] )  \n",
        "\n",
        "        scaler = StandardScaler()\n",
        "        X_train=scaler.fit_transform(X_train)\n",
        "        X_test=scaler.transform(X_test)\n",
        "\n",
        "        clf.fit(X_train,y_train)\n",
        "        y_pred = clf.predict(X_test)\n",
        "        accuracy=accuracy_score(y_test, y_pred)\n",
        "        clf_acc.append(accuracy)\n",
        "    print('mean',np.array(clf_acc).mean())    \n",
        "    raw_acc.append(np.array(clf_acc).mean())\n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==============================\n",
            "KNeighborsClassifier\n",
            "mean 0.5566071428571429\n",
            "==============================\n",
            "SVC\n",
            "mean 0.5758928571428571\n",
            "==============================\n",
            "NuSVC\n",
            "mean 0.5599999999999999\n",
            "==============================\n",
            "DecisionTreeClassifier\n",
            "mean 0.5383928571428571\n",
            "==============================\n",
            "RandomForestClassifier\n",
            "mean 0.5683928571428571\n",
            "==============================\n",
            "AdaBoostClassifier\n",
            "mean 0.614107142857143\n",
            "==============================\n",
            "GradientBoostingClassifier\n",
            "mean 0.6139285714285715\n",
            "==============================\n",
            "GaussianNB\n",
            "mean 0.5907142857142857\n",
            "==============================\n",
            "LinearDiscriminantAnalysis\n",
            "mean 0.5069642857142858\n",
            "==============================\n",
            "QuadraticDiscriminantAnalysis\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "mean 0.48964285714285716\n",
            "==============================\n",
            "LogisticRegression\n",
            "mean 0.5360714285714285\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sagRkTZHlmAT",
        "colab_type": "code",
        "outputId": "513f1eec-b6bb-4445-87c5-28fd02a45d71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "raw_acc"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5566071428571429,\n",
              " 0.5758928571428571,\n",
              " 0.5599999999999999,\n",
              " 0.5398214285714286,\n",
              " 0.5366071428571428,\n",
              " 0.614107142857143,\n",
              " 0.6125,\n",
              " 0.5907142857142857,\n",
              " 0.5069642857142858,\n",
              " 0.48964285714285716,\n",
              " 0.5360714285714285]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "icpqu9V5D1EL",
        "colab_type": "code",
        "outputId": "db78665b-ac22-44c8-ae11-84995f0aad8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "classifier=['KNN','SVC','nuSCV','DT','RF','Ada','GB','NB','LDA','QDA','LR']\n",
        "y_pos = np.arange(len(classifier))\n",
        "plt.bar(y_pos,np.array(raw_acc))\n",
        "plt.xticks(y_pos, classifier)\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Classifiers')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Classifiers')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEICAYAAABS0fM3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlyCIiGi5BEFERMslCCIiWu4/AVIgOyCmsSr8AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBDXxRp2O5kO",
        "colab_type": "text"
      },
      "source": [
        "# Principle Component Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGWFC54TO44u",
        "colab_type": "code",
        "outputId": "031bd969-4e84-4614-f70c-6f2b30185d0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        }
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import KernelPCA\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "#Fitting the PCA algorithm with our Data\n",
        "pca = PCA().fit(X)\n",
        "#Plotting the Cumulative Summation of the Explained Variance\n",
        "plt.figure()\n",
        "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
        "plt.xlabel('Number of Components')\n",
        "plt.ylabel('Variance (%)') #for each component\n",
        "plt.title('EEG')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-79-55176e33abb8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#Fitting the PCA algorithm with our Data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mpca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPCA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;31m#Plotting the Cumulative Summation of the Explained Variance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/decomposition/pca.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    339\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minstance\u001b[0m \u001b[0mitself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m         \"\"\"\n\u001b[0;32m--> 341\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/decomposition/pca.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m         X = check_array(X, dtype=[np.float64, np.float32], ensure_2d=True,\n\u001b[0;32m--> 382\u001b[0;31m                         copy=self.copy)\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0;31m# Handle n_components==None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    537\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_nd\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m             raise ValueError(\"Found array with dim %d. %s expected <= 2.\"\n\u001b[0;32m--> 539\u001b[0;31m                              % (array.ndim, estimator_name))\n\u001b[0m\u001b[1;32m    540\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m             _assert_all_finite(array,\n",
            "\u001b[0;31mValueError\u001b[0m: Found array with dim 3. Estimator expected <= 2."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SN4VeHRtO__B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2vhCPXYMohbm",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "scalar = StandardScaler()\n",
        "clf = SVC(kernel='rbf')\n",
        "pca = PCA(n_components=20)\n",
        "\n",
        "pipeline = Pipeline([('selector',pca), ('estimator', clf)])\n",
        "#pipeline = Pipeline([('transformer', scalar),('selector',rfe), ('estimator', clf)])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ij17b3omqHn",
        "colab_type": "code",
        "outputId": "49e40540-fa51-48d9-9b99-e9f67621cbc0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        }
      },
      "source": [
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "pca_acc=[]\n",
        "skf = StratifiedKFold(n_splits=5)\n",
        "skf.get_n_splits(X, y)\n",
        "for clf in classifiers:\n",
        "    name = clf.__class__.__name__\n",
        "    clf_acc=[]\n",
        "\n",
        "    print(\"=\"*30)\n",
        "    print(name)       \n",
        "    for train_index, test_index in skf.split(X, y):\n",
        "        X_train, X_test = X[train_index], X[test_index]\n",
        "        y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "        X_train=X_train.reshape(-1,450)\n",
        "        X_test=X_test.reshape(-1,450)\n",
        "\n",
        "        y_train = np.array( [ele for ele in y_train for i in range(10)] )\n",
        "        y_test =np.array([ele for ele in y_test for i in range(10)] )  \n",
        "# Apply standard scaler\n",
        "        scaler = StandardScaler()\n",
        "        X_train=scaler.fit_transform(X_train)\n",
        "        X_test=scaler.transform(X_test)\n",
        "#Apply PCA\n",
        "        pca = PCA(n_components=20)\n",
        "        X_train=pca.fit_transform(X_train)\n",
        "        X_test=pca.transform(X_test)\n",
        "#Apply classification\n",
        "        clf.fit(X_train,y_train)\n",
        "        y_pred = clf.predict(X_test)\n",
        "        accuracy=accuracy_score(y_test, y_pred)\n",
        "        clf_acc.append(accuracy)\n",
        "    print('mean',np.array(clf_acc).mean())    \n",
        "    pca_acc.append(np.array(clf_acc).mean())\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==============================\n",
            "KNeighborsClassifier\n",
            "mean 0.573392857142857\n",
            "==============================\n",
            "SVC\n",
            "mean 0.5294642857142857\n",
            "==============================\n",
            "NuSVC\n",
            "mean 0.5421428571428571\n",
            "==============================\n",
            "DecisionTreeClassifier\n",
            "mean 0.5594642857142856\n",
            "==============================\n",
            "RandomForestClassifier\n",
            "mean 0.6007142857142858\n",
            "==============================\n",
            "AdaBoostClassifier\n",
            "mean 0.6094642857142858\n",
            "==============================\n",
            "GradientBoostingClassifier\n",
            "mean 0.5878571428571429\n",
            "==============================\n",
            "GaussianNB\n",
            "mean 0.6328571428571428\n",
            "==============================\n",
            "LinearDiscriminantAnalysis\n",
            "mean 0.6483928571428571\n",
            "==============================\n",
            "QuadraticDiscriminantAnalysis\n",
            "mean 0.57125\n",
            "==============================\n",
            "LogisticRegression\n",
            "mean 0.6460714285714285\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2PaVKiKhAyf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34K17oX2kI3Z",
        "colab_type": "text"
      },
      "source": [
        "# RFE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Effk-fW1km3b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import MaxAbsScaler,StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_selection import RFE\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19-Hb0ohkM5k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classifiers = [\n",
        "    KNeighborsClassifier(3),\n",
        "    SVC(kernel=\"rbf\"),\n",
        "    NuSVC(),\n",
        "    DecisionTreeClassifier(),\n",
        "    RandomForestClassifier(),\n",
        "    AdaBoostClassifier(),\n",
        "    GradientBoostingClassifier(),\n",
        "    GaussianNB(),\n",
        "    LinearDiscriminantAnalysis(),\n",
        "    QuadraticDiscriminantAnalysis(),\n",
        "    LogisticRegression()]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X3joTTYvkPfz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "clf = SVC(kernel='rbf')\n",
        "rfe=RFE(SVC(kernel='linear'),n_features_to_select=50,step=10,verbose=0)   \n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S37vDSnpkpi-",
        "colab_type": "code",
        "outputId": "38455015-00c8-4459-ca6b-2a122992eba5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        }
      },
      "source": [
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "rfe_acc=[]\n",
        "skf = StratifiedKFold(n_splits=5)\n",
        "skf.get_n_splits(X, y)\n",
        "for clf in classifiers:\n",
        "    name = clf.__class__.__name__\n",
        "    clf_acc=[]\n",
        "\n",
        "    print(\"=\"*30)\n",
        "    print(name)       \n",
        "    for train_index, test_index in skf.split(X, y):\n",
        "        X_train, X_test = X[train_index], X[test_index]\n",
        "        y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "        X_train=X_train.reshape(-1,450)\n",
        "        X_test=X_test.reshape(-1,450)\n",
        "\n",
        "        y_train = np.array( [ele for ele in y_train for i in range(10)] )\n",
        "        y_test =np.array([ele for ele in y_test for i in range(10)] )  \n",
        "# Apply standard scaler\n",
        "        scaler = StandardScaler()\n",
        "        X_train=scaler.fit_transform(X_train)\n",
        "        X_test=scaler.transform(X_test)\n",
        "#Apply RFE\n",
        "        X_train=rfe.fit_transform(X_train,y_train)\n",
        "        X_test=rfe.transform(X_test)\n",
        "#Apply classification\n",
        "        clf.fit(X_train,y_train)\n",
        "        y_pred = clf.predict(X_test)\n",
        "        accuracy=accuracy_score(y_test, y_pred)\n",
        "        clf_acc.append(accuracy)\n",
        "    print('mean',np.array(clf_acc).mean())    \n",
        "    rfe_acc.append(np.array(clf_acc).mean())\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==============================\n",
            "KNeighborsClassifier\n",
            "mean 0.48464285714285715\n",
            "==============================\n",
            "SVC\n",
            "mean 0.5235714285714286\n",
            "==============================\n",
            "NuSVC\n",
            "mean 0.5176785714285714\n",
            "==============================\n",
            "DecisionTreeClassifier\n",
            "mean 0.5183928571428572\n",
            "==============================\n",
            "RandomForestClassifier\n",
            "mean 0.5839285714285715\n",
            "==============================\n",
            "AdaBoostClassifier\n",
            "mean 0.5626785714285714\n",
            "==============================\n",
            "GradientBoostingClassifier\n",
            "mean 0.5621428571428572\n",
            "==============================\n",
            "GaussianNB\n",
            "mean 0.5871428571428571\n",
            "==============================\n",
            "LinearDiscriminantAnalysis\n",
            "mean 0.49607142857142855\n",
            "==============================\n",
            "QuadraticDiscriminantAnalysis\n",
            "mean 0.41785714285714287\n",
            "==============================\n",
            "LogisticRegression\n",
            "mean 0.5314285714285714\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5yNkL4arI5Z",
        "colab_type": "text"
      },
      "source": [
        "# SKbest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5wEC_ForKGR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import f_classif\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "r5vNJstWrtCD",
        "colab": {}
      },
      "source": [
        "\n",
        "scalar = StandardScaler()\n",
        "clf = SVC(kernel='rbf')\n",
        "skbest=SelectKBest(f_classif, k=20)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "a91a0a35-1188-4288-ffb3-67d0e9c8bae7",
        "id": "4VS9cTTirtCH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        }
      },
      "source": [
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "skbest_acc=[]\n",
        "skf = StratifiedKFold(n_splits=5)\n",
        "skf.get_n_splits(X, y)\n",
        "for clf in classifiers:\n",
        "    name = clf.__class__.__name__\n",
        "    clf_acc=[]\n",
        "\n",
        "    print(\"=\"*30)\n",
        "    print(name)       \n",
        "    for train_index, test_index in skf.split(X, y):\n",
        "        X_train, X_test = X[train_index], X[test_index]\n",
        "        y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "        X_train=X_train.reshape(-1,450)\n",
        "        X_test=X_test.reshape(-1,450)\n",
        "\n",
        "        y_train = np.array( [ele for ele in y_train for i in range(10)] )\n",
        "        y_test =np.array([ele for ele in y_test for i in range(10)] )  \n",
        "# Apply standard scaler\n",
        "        scaler = StandardScaler()\n",
        "        X_train=scaler.fit_transform(X_train)\n",
        "        X_test=scaler.transform(X_test)\n",
        "#Apply Skbest\n",
        "        X_train=skbest.fit_transform(X_train,y_train)\n",
        "        X_test=skbest.transform(X_test)\n",
        "#Apply classification\n",
        "        clf.fit(X_train,y_train)\n",
        "        y_pred = clf.predict(X_test)\n",
        "        accuracy=accuracy_score(y_test, y_pred)\n",
        "        clf_acc.append(accuracy)\n",
        "    print('mean',np.array(clf_acc).mean())    \n",
        "    skbest_acc.append(np.array(clf_acc).mean())\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==============================\n",
            "KNeighborsClassifier\n",
            "mean 0.5014285714285714\n",
            "==============================\n",
            "SVC\n",
            "mean 0.5323214285714286\n",
            "==============================\n",
            "NuSVC\n",
            "mean 0.5221428571428571\n",
            "==============================\n",
            "DecisionTreeClassifier\n",
            "mean 0.5123214285714286\n",
            "==============================\n",
            "RandomForestClassifier\n",
            "mean 0.5451785714285714\n",
            "==============================\n",
            "AdaBoostClassifier\n",
            "mean 0.5253571428571429\n",
            "==============================\n",
            "GradientBoostingClassifier\n",
            "mean 0.5342857142857144\n",
            "==============================\n",
            "GaussianNB\n",
            "mean 0.5310714285714285\n",
            "==============================\n",
            "LinearDiscriminantAnalysis\n",
            "mean 0.5458928571428572\n",
            "==============================\n",
            "QuadraticDiscriminantAnalysis\n",
            "mean 0.4367857142857143\n",
            "==============================\n",
            "LogisticRegression\n",
            "mean 0.5432142857142858\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wbl3_Cs9rnNh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N40_Zc8nsiU3",
        "colab_type": "text"
      },
      "source": [
        "# VarianceThreshold"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hqPon3DushYn",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_selection import VarianceThreshold\n",
        "scalar = StandardScaler()\n",
        "clf = SVC(kernel='rbf')\n",
        "algo=selector = VarianceThreshold()\n",
        "pipeline = Pipeline([('selector',algo), ('estimator', clf)])\n",
        "#pipeline = Pipeline([('transformer', scalar),('selector',rfe), ('estimator', clf)])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "3c2ad755-e721-4060-c9a6-16dfe27198b6",
        "id": "zH6sK58CshYp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "accuracy_var=[]\n",
        "std_var=[]\n",
        "f1_scores=[]\n",
        "f1_scores_std=[]\n",
        "for clfs in classifiers:\n",
        "    pipeline.set_params(estimator = clfs)\n",
        "    name = clfs.__class__.__name__\n",
        "    \n",
        "    print(\"=\"*30)\n",
        "    print(name)       \n",
        "    print('****Results****')\n",
        "    scores = cross_val_score(pipeline, X, y, cv=5)\n",
        "    #f1_score = cross_val_score(clf, X_rfe, y, cv=5,scoring='f1')\n",
        "    print(\"Accuracy: {:.4%}\".format(np.array(scores).mean()))\n",
        "    accuracy_var.append(np.array(scores).mean())\n",
        "    std_var.append(np.array(scores).std())\n",
        "    #f1_scores.append(np.array(f1_score).mean())\n",
        "    #f1_scores_std.append(np.array(f1_score).std())\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==============================\n",
            "KNeighborsClassifier\n",
            "****Results****\n",
            "Accuracy: 72.3214%\n",
            "==============================\n",
            "SVC\n",
            "****Results****\n",
            "Accuracy: 63.9286%\n",
            "==============================\n",
            "NuSVC\n",
            "****Results****\n",
            "Accuracy: 70.7143%\n",
            "==============================\n",
            "DecisionTreeClassifier\n",
            "****Results****\n",
            "Accuracy: 50.8929%\n",
            "==============================\n",
            "RandomForestClassifier\n",
            "****Results****\n",
            "Accuracy: 56.7857%\n",
            "==============================\n",
            "AdaBoostClassifier\n",
            "****Results****\n",
            "Accuracy: 61.2500%\n",
            "==============================\n",
            "GradientBoostingClassifier\n",
            "****Results****\n",
            "Accuracy: 57.3214%\n",
            "==============================\n",
            "GaussianNB\n",
            "****Results****\n",
            "Accuracy: 62.1429%\n",
            "==============================\n",
            "LinearDiscriminantAnalysis\n",
            "****Results****\n",
            "Accuracy: 75.0000%\n",
            "==============================\n",
            "QuadraticDiscriminantAnalysis\n",
            "****Results****\n",
            "Accuracy: 43.0357%\n",
            "==============================\n",
            "LogisticRegression\n",
            "****Results****\n",
            "Accuracy: 70.8929%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
            "  warnings.warn(\"Variables are collinear.\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
            "  warnings.warn(\"Variables are collinear.\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
            "  warnings.warn(\"Variables are collinear.\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
            "  warnings.warn(\"Variables are collinear.\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
            "  warnings.warn(\"Variables are collinear.\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9-EzT5grnQp",
        "colab_type": "code",
        "outputId": "79c9f20e-a5bc-42e2-90dc-d36bd25fb6c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(accuracy),len(accuracy_pca),len(accuracy_rfe),len(accuracy_kbest),len(accuracy_var)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11, 11, 11, 27, 11)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mtlBCPBtZjDm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result=pd.DataFrame([accuracy,accuracy_pca,accuracy_rfe,accuracy_kbest,accuracy_var],\n",
        "                    index=['Accuracy','PCA',\"RFE\",'kbest','VAR'],\n",
        "                    columns=['KNN','SVC','nuSCV','DT','RF','Ada','GB','NB','LDA','QDA','LR'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oDxtmxamaD9y",
        "colab_type": "code",
        "outputId": "becf837b-fb80-4816-a335-e2e12d7cfc19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        }
      },
      "source": [
        "result.T"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>PCA</th>\n",
              "      <th>RFE</th>\n",
              "      <th>kbest</th>\n",
              "      <th>VAR</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>KNN</th>\n",
              "      <td>0.723214</td>\n",
              "      <td>0.723214</td>\n",
              "      <td>0.614286</td>\n",
              "      <td>0.723214</td>\n",
              "      <td>0.723214</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SVC</th>\n",
              "      <td>0.639286</td>\n",
              "      <td>0.667857</td>\n",
              "      <td>0.680357</td>\n",
              "      <td>0.639286</td>\n",
              "      <td>0.639286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nuSCV</th>\n",
              "      <td>0.707143</td>\n",
              "      <td>0.721429</td>\n",
              "      <td>0.794643</td>\n",
              "      <td>0.707143</td>\n",
              "      <td>0.707143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DT</th>\n",
              "      <td>0.537500</td>\n",
              "      <td>0.664286</td>\n",
              "      <td>0.496429</td>\n",
              "      <td>0.567857</td>\n",
              "      <td>0.508929</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RF</th>\n",
              "      <td>0.621429</td>\n",
              "      <td>0.564286</td>\n",
              "      <td>0.707143</td>\n",
              "      <td>0.567857</td>\n",
              "      <td>0.567857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Ada</th>\n",
              "      <td>0.612500</td>\n",
              "      <td>0.623214</td>\n",
              "      <td>0.582143</td>\n",
              "      <td>0.612500</td>\n",
              "      <td>0.612500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GB</th>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.651786</td>\n",
              "      <td>0.619643</td>\n",
              "      <td>0.637500</td>\n",
              "      <td>0.573214</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NB</th>\n",
              "      <td>0.621429</td>\n",
              "      <td>0.664286</td>\n",
              "      <td>0.664286</td>\n",
              "      <td>0.621429</td>\n",
              "      <td>0.621429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LDA</th>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.733929</td>\n",
              "      <td>0.651786</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.750000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>QDA</th>\n",
              "      <td>0.430357</td>\n",
              "      <td>0.607143</td>\n",
              "      <td>0.541071</td>\n",
              "      <td>0.430357</td>\n",
              "      <td>0.430357</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LR</th>\n",
              "      <td>0.708929</td>\n",
              "      <td>0.707143</td>\n",
              "      <td>0.725000</td>\n",
              "      <td>0.708929</td>\n",
              "      <td>0.708929</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Accuracy       PCA       RFE     kbest       VAR\n",
              "KNN    0.723214  0.723214  0.614286  0.723214  0.723214\n",
              "SVC    0.639286  0.667857  0.680357  0.639286  0.639286\n",
              "nuSCV  0.707143  0.721429  0.794643  0.707143  0.707143\n",
              "DT     0.537500  0.664286  0.496429  0.567857  0.508929\n",
              "RF     0.621429  0.564286  0.707143  0.567857  0.567857\n",
              "Ada    0.612500  0.623214  0.582143  0.612500  0.612500\n",
              "GB     0.625000  0.651786  0.619643  0.637500  0.573214\n",
              "NB     0.621429  0.664286  0.664286  0.621429  0.621429\n",
              "LDA    0.750000  0.733929  0.651786  0.750000  0.750000\n",
              "QDA    0.430357  0.607143  0.541071  0.430357  0.430357\n",
              "LR     0.708929  0.707143  0.725000  0.708929  0.708929"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-IOzjP1bGBu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}