{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras-metrics\n",
      "  Downloading https://files.pythonhosted.org/packages/32/c9/a87420da8e73de944e63a8e9cdcfb1f03ca31a7c4cdcdbd45d2cdf13275a/keras_metrics-1.1.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: Keras>=2.1.5 in c:\\anaconda3\\envs\\deep\\lib\\site-packages (from keras-metrics) (2.2.4)\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\anaconda3\\envs\\deep\\lib\\site-packages (from Keras>=2.1.5->keras-metrics) (1.16.5)\n",
      "Requirement already satisfied: scipy>=0.14 in c:\\anaconda3\\envs\\deep\\lib\\site-packages (from Keras>=2.1.5->keras-metrics) (1.3.1)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\anaconda3\\envs\\deep\\lib\\site-packages (from Keras>=2.1.5->keras-metrics) (1.12.0)\n",
      "Requirement already satisfied: pyyaml in c:\\anaconda3\\envs\\deep\\lib\\site-packages (from Keras>=2.1.5->keras-metrics) (5.1.2)\n",
      "Requirement already satisfied: h5py in c:\\anaconda3\\envs\\deep\\lib\\site-packages (from Keras>=2.1.5->keras-metrics) (2.8.0)\n",
      "Requirement already satisfied: keras_applications>=1.0.6 in c:\\anaconda3\\envs\\deep\\lib\\site-packages (from Keras>=2.1.5->keras-metrics) (1.0.8)\n",
      "Requirement already satisfied: keras_preprocessing>=1.0.5 in c:\\anaconda3\\envs\\deep\\lib\\site-packages (from Keras>=2.1.5->keras-metrics) (1.1.0)\n",
      "Installing collected packages: keras-metrics\n",
      "Successfully installed keras-metrics-1.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install keras-metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import progressbar\n",
    "import re\n",
    "import mne\n",
    "from scipy import stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv1D,MaxPooling1D,Dropout,BatchNormalization,GlobalAveragePooling1D\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import model_from_json\n",
    "from keras import backend as K\n",
    "from keras.layers import LeakyReLU\n",
    "#import keras_metrics as km\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from D:\\Datasets\\EEG dataset\\mental artithematic\\data\\Subject00_1.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 90999  =      0.000 ...   181.998 secs...\n",
      "Extracting EDF parameters from D:\\Datasets\\EEG dataset\\mental artithematic\\data\\Subject00_2.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n",
      "Extracting EDF parameters from D:\\Datasets\\EEG dataset\\mental artithematic\\data\\Subject01_1.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 90999  =      0.000 ...   181.998 secs...\n",
      "Extracting EDF parameters from D:\\Datasets\\EEG dataset\\mental artithematic\\data\\Subject01_2.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n",
      "Extracting EDF parameters from D:\\Datasets\\EEG dataset\\mental artithematic\\data\\Subject02_1.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 90999  =      0.000 ...   181.998 secs...\n",
      "Extracting EDF parameters from D:\\Datasets\\EEG dataset\\mental artithematic\\data\\Subject02_2.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n",
      "Extracting EDF parameters from D:\\Datasets\\EEG dataset\\mental artithematic\\data\\Subject03_1.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 90999  =      0.000 ...   181.998 secs...\n",
      "Extracting EDF parameters from D:\\Datasets\\EEG dataset\\mental artithematic\\data\\Subject03_2.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n",
      "Extracting EDF parameters from D:\\Datasets\\EEG dataset\\mental artithematic\\data\\Subject04_1.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 84999  =      0.000 ...   169.998 secs...\n",
      "Extracting EDF parameters from D:\\Datasets\\EEG dataset\\mental artithematic\\data\\Subject04_2.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n",
      "Extracting EDF parameters from D:\\Datasets\\EEG dataset\\mental artithematic\\data\\Subject05_1.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 90999  =      0.000 ...   181.998 secs...\n",
      "Extracting EDF parameters from D:\\Datasets\\EEG dataset\\mental artithematic\\data\\Subject05_2.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n",
      "Extracting EDF parameters from D:\\Datasets\\EEG dataset\\mental artithematic\\data\\Subject06_1.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 90999  =      0.000 ...   181.998 secs...\n",
      "Extracting EDF parameters from D:\\Datasets\\EEG dataset\\mental artithematic\\data\\Subject06_2.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n",
      "Extracting EDF parameters from D:\\Datasets\\EEG dataset\\mental artithematic\\data\\Subject07_1.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 90999  =      0.000 ...   181.998 secs...\n",
      "Extracting EDF parameters from D:\\Datasets\\EEG dataset\\mental artithematic\\data\\Subject07_2.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n",
      "Extracting EDF parameters from D:\\Datasets\\EEG dataset\\mental artithematic\\data\\Subject08_1.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 90999  =      0.000 ...   181.998 secs...\n",
      "Extracting EDF parameters from D:\\Datasets\\EEG dataset\\mental artithematic\\data\\Subject08_2.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n",
      "Extracting EDF parameters from D:\\Datasets\\EEG dataset\\mental artithematic\\data\\Subject09_1.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 90999  =      0.000 ...   181.998 secs...\n",
      "Extracting EDF parameters from D:\\Datasets\\EEG dataset\\mental artithematic\\data\\Subject09_2.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n",
      "Extracting EDF parameters from D:\\Datasets\\EEG dataset\\mental artithematic\\data\\Subject10_1.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 93999  =      0.000 ...   187.998 secs...\n",
      "Extracting EDF parameters from D:\\Datasets\\EEG dataset\\mental artithematic\\data\\Subject10_2.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n",
      "Extracting EDF parameters from D:\\Datasets\\EEG dataset\\mental artithematic\\data\\Subject11_1.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 90999  =      0.000 ...   181.998 secs...\n",
      "Extracting EDF parameters from D:\\Datasets\\EEG dataset\\mental artithematic\\data\\Subject11_2.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n",
      "Extracting EDF parameters from D:\\Datasets\\EEG dataset\\mental artithematic\\data\\Subject12_1.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 90999  =      0.000 ...   181.998 secs...\n",
      "Extracting EDF parameters from D:\\Datasets\\EEG dataset\\mental artithematic\\data\\Subject12_2.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n",
      "Extracting EDF parameters from D:\\Datasets\\EEG dataset\\mental artithematic\\data\\Subject13_1.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 90999  =      0.000 ...   181.998 secs...\n",
      "Extracting EDF parameters from D:\\Datasets\\EEG dataset\\mental artithematic\\data\\Subject13_2.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n",
      "Extracting EDF parameters from D:\\Datasets\\EEG dataset\\mental artithematic\\data\\Subject14_1.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 90999  =      0.000 ...   181.998 secs...\n",
      "Extracting EDF parameters from D:\\Datasets\\EEG dataset\\mental artithematic\\data\\Subject14_2.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n",
      "Extracting EDF parameters from D:\\Datasets\\EEG dataset\\mental artithematic\\data\\Subject15_1.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 90999  =      0.000 ...   181.998 secs...\n",
      "Extracting EDF parameters from D:\\Datasets\\EEG dataset\\mental artithematic\\data\\Subject15_2.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n",
      "Extracting EDF parameters from D:\\Datasets\\EEG dataset\\mental artithematic\\data\\Subject16_1.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 90999  =      0.000 ...   181.998 secs...\n",
      "Extracting EDF parameters from D:\\Datasets\\EEG dataset\\mental artithematic\\data\\Subject16_2.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n",
      "Extracting EDF parameters from D:\\Datasets\\EEG dataset\\mental artithematic\\data\\Subject17_1.edf...\n",
      "EDF file detected\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 90999  =      0.000 ...   181.998 secs...\n",
      "Extracting EDF parameters from D:\\Datasets\\EEG dataset\\mental artithematic\\data\\Subject17_2.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n",
      "Extracting EDF parameters from D:\\Datasets\\EEG dataset\\mental artithematic\\data\\Subject18_1.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 90999  =      0.000 ...   181.998 secs...\n",
      "Extracting EDF parameters from D:\\Datasets\\EEG dataset\\mental artithematic\\data\\Subject18_2.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n",
      "Extracting EDF parameters from D:\\Datasets\\EEG dataset\\mental artithematic\\data\\Subject19_1.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 90999  =      0.000 ...   181.998 secs...\n",
      "Extracting EDF parameters from D:\\Datasets\\EEG dataset\\mental artithematic\\data\\Subject19_2.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n",
      "Extracting EDF parameters from D:\\Datasets\\EEG dataset\\mental artithematic\\data\\Subject20_1.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 90999  =      0.000 ...   181.998 secs...\n",
      "Extracting EDF parameters from D:\\Datasets\\EEG dataset\\mental artithematic\\data\\Subject20_2.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n",
      "Extracting EDF parameters from D:\\Datasets\\EEG dataset\\mental artithematic\\data\\Subject21_1.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 90999  =      0.000 ...   181.998 secs...\n",
      "Extracting EDF parameters from D:\\Datasets\\EEG dataset\\mental artithematic\\data\\Subject21_2.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n",
      "Extracting EDF parameters from D:\\Datasets\\EEG dataset\\mental artithematic\\data\\Subject22_1.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 90999  =      0.000 ...   181.998 secs...\n",
      "Extracting EDF parameters from D:\\Datasets\\EEG dataset\\mental artithematic\\data\\Subject22_2.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n",
      "Extracting EDF parameters from D:\\Datasets\\EEG dataset\\mental artithematic\\data\\Subject23_1.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 90999  =      0.000 ...   181.998 secs...\n",
      "Extracting EDF parameters from D:\\Datasets\\EEG dataset\\mental artithematic\\data\\Subject23_2.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n",
      "Extracting EDF parameters from D:\\Datasets\\EEG dataset\\mental artithematic\\data\\Subject24_1.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 90999  =      0.000 ...   181.998 secs...\n",
      "Extracting EDF parameters from D:\\Datasets\\EEG dataset\\mental artithematic\\data\\Subject24_2.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n",
      "Extracting EDF parameters from D:\\Datasets\\EEG dataset\\mental artithematic\\data\\Subject25_1.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 90999  =      0.000 ...   181.998 secs...\n",
      "Extracting EDF parameters from D:\\Datasets\\EEG dataset\\mental artithematic\\data\\Subject25_2.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n",
      "Extracting EDF parameters from D:\\Datasets\\EEG dataset\\mental artithematic\\data\\Subject26_1.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 90999  =      0.000 ...   181.998 secs...\n",
      "Extracting EDF parameters from D:\\Datasets\\EEG dataset\\mental artithematic\\data\\Subject26_2.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n",
      "Extracting EDF parameters from D:\\Datasets\\EEG dataset\\mental artithematic\\data\\Subject27_1.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 90999  =      0.000 ...   181.998 secs...\n",
      "Extracting EDF parameters from D:\\Datasets\\EEG dataset\\mental artithematic\\data\\Subject27_2.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n",
      "Extracting EDF parameters from D:\\Datasets\\EEG dataset\\mental artithematic\\data\\Subject28_1.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 90999  =      0.000 ...   181.998 secs...\n",
      "Extracting EDF parameters from D:\\Datasets\\EEG dataset\\mental artithematic\\data\\Subject28_2.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n",
      "Extracting EDF parameters from D:\\Datasets\\EEG dataset\\mental artithematic\\data\\Subject29_1.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 90999  =      0.000 ...   181.998 secs...\n",
      "Extracting EDF parameters from D:\\Datasets\\EEG dataset\\mental artithematic\\data\\Subject29_2.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n",
      "Extracting EDF parameters from D:\\Datasets\\EEG dataset\\mental artithematic\\data\\Subject30_1.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 90999  =      0.000 ...   181.998 secs...\n",
      "Extracting EDF parameters from D:\\Datasets\\EEG dataset\\mental artithematic\\data\\Subject30_2.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n",
      "Extracting EDF parameters from D:\\Datasets\\EEG dataset\\mental artithematic\\data\\Subject31_1.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 39999  =      0.000 ...    79.998 secs...\n",
      "Extracting EDF parameters from D:\\Datasets\\EEG dataset\\mental artithematic\\data\\Subject31_2.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n",
      "Extracting EDF parameters from D:\\Datasets\\EEG dataset\\mental artithematic\\data\\Subject32_1.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 90999  =      0.000 ...   181.998 secs...\n",
      "Extracting EDF parameters from D:\\Datasets\\EEG dataset\\mental artithematic\\data\\Subject32_2.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n",
      "Extracting EDF parameters from D:\\Datasets\\EEG dataset\\mental artithematic\\data\\Subject33_1.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 90999  =      0.000 ...   181.998 secs...\n",
      "Extracting EDF parameters from D:\\Datasets\\EEG dataset\\mental artithematic\\data\\Subject33_2.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n",
      "Extracting EDF parameters from D:\\Datasets\\EEG dataset\\mental artithematic\\data\\Subject34_1.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 90999  =      0.000 ...   181.998 secs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from D:\\Datasets\\EEG dataset\\mental artithematic\\data\\Subject34_2.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n",
      "Extracting EDF parameters from D:\\Datasets\\EEG dataset\\mental artithematic\\data\\Subject35_1.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 90999  =      0.000 ...   181.998 secs...\n",
      "Extracting EDF parameters from D:\\Datasets\\EEG dataset\\mental artithematic\\data\\Subject35_2.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "path = r'D:/Datasets/EEG dataset/mental artithematic/data/' # use your path\n",
    "all_files = glob.glob(os.path.join(path, \"*.edf\")) \n",
    "\n",
    "data1=[]\n",
    "data2=[]\n",
    "for filename in (all_files):\n",
    "    if int(re.findall(r'\\d+',filename)[1])==1:\n",
    "        data1.append(mne.io.read_raw_edf(filename,preload=True).get_data()[0:-3,::]);\n",
    "    else:\n",
    "        data2.append(mne.io.read_raw_edf(filename,preload=True).get_data()[0:-3,::]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18, 91000)"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1x=[]\n",
    "data2x=[]\n",
    "for i in range(36):\n",
    "    data1x.append(stats.zscore(data1[i] ))\n",
    "for i in range(36):\n",
    "    data2x.append(stats.zscore(data2[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1=data1x.copy()\n",
    "test1 = train1[0:5]\n",
    "del train1[0:5]\n",
    "train2=data2x.copy()\n",
    "test2 = train2[0:5]\n",
    "del train2[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n",
      "5\n",
      "31\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "print(len(train1))\n",
    "print(len(test1))\n",
    "print(len(train2))\n",
    "print(len(test2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=0\n",
    "sample=500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_1=[] #add pca after train1 \n",
    "for i in range(len(train1)):\n",
    "    train_1.append(np.reshape(train1[i],(-1,sample,18)))\n",
    "train_2=[]\n",
    "for i in range(len(train2)):\n",
    "    train_2.append(np.reshape(train2[i],(-1,sample,18)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_1=[]\n",
    "for i in range(len(test1)):\n",
    "    test_1.append(np.reshape(test1[i],(-1,sample,18)))\n",
    "test_2=[]\n",
    "for i in range(len(test1)):\n",
    "    test_2.append(np.reshape(test2[i],(-1,sample,18)))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((182, 500, 18), (62, 500, 18))"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_1[0].shape,train_2[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5546, 500, 18) (1922, 500, 18)\n"
     ]
    }
   ],
   "source": [
    "data1_train=np.concatenate(train_1,axis=0)\n",
    "data2_train=np.concatenate(train_2,axis=0)\n",
    "print(data1_train.shape,data2_train.shape)\n",
    "X_train=np.concatenate((data1_train,data2_train),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(898, 500, 18) (310, 500, 18)\n"
     ]
    }
   ],
   "source": [
    "data1_test=np.concatenate(test_1,axis=0)\n",
    "data2_test=np.concatenate(test_2,axis=0)\n",
    "print(data1_test.shape,data2_test.shape)\n",
    "X_test=np.concatenate((data1_test,data2_test),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #3D tensor with shape: (batch, steps, channels)\n",
    "# X_train=np.swapaxes(X_train,0,1)\n",
    "# X_test=np.swapaxes(X_test,0,1)\n",
    "# print(X_train.shape,X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1=np.zeros(data1_train.shape[0])\n",
    "y2=np.ones(data2_train.shape[0])\n",
    "y_train=np.concatenate((y1,y2),axis=0)\n",
    "y1=np.zeros(data1_test.shape[0])\n",
    "y2=np.ones(data2_test.shape[0])\n",
    "y_test=np.concatenate((y1,y2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7468, 500, 18), (1208, 500, 18))"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape,X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7468,), (1208,))"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx=np.random.RandomState(seed=seed).permutation(len(y_train))\n",
    "X_train=X_train[idx]\n",
    "y_train=y_train[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx=np.random.RandomState(seed=seed).permutation(len(y_test))\n",
    "X_test=X_test[idx]\n",
    "y_test=y_test[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train=np.reshape(X_train,(X_train.shape[0], sample,1))\n",
    "# X_test=np.reshape(X_test,(X_test.shape[0], sample,1))\n",
    "\n",
    "# print(X_train.shape,X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=keras.utils.to_categorical(y_train,2)\n",
    "y_test=keras.utils.to_categorical(y_test,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1208, 2), (7468, 2))"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape,y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv1D(16, (8), input_shape=(sample,18)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.add(Conv1D(6, (8)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "\n",
    "#model.add(MaxPooling1D(pool_size=2,strides=2,padding='same'))\n",
    "\n",
    "#model.add(Conv1D(10, (14), activation='relu',padding='same'))\n",
    "\n",
    "#model.add(MaxPooling1D(pool_size=2,strides=2,padding='same'))\n",
    "\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Flatten())\n",
    "#model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dense(2, activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.binary_crossentropy,\n",
    "              optimizer=keras.optimizers.Adam(lr=0.0001),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 493, 16)           2320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 493, 16)           64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 493, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 486, 6)            774       \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 486, 6)            24        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 486, 6)            0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 486, 6)            0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2916)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 20)                58340     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 61,564\n",
      "Trainable params: 61,520\n",
      "Non-trainable params: 44\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count number of parameters in the model\n",
    "numParams    = model.count_params()    \n",
    "\n",
    "# set a valid path for your system to record model checkpoints\n",
    "checkpointer = ModelCheckpoint(filepath='checkpoint.h5', verbose=1,\n",
    "                               save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = {0:1, 1:2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7468 samples, validate on 1208 samples\n",
      "Epoch 1/30\n",
      " - 10s - loss: 0.9301 - acc: 0.6022 - val_loss: 0.6478 - val_acc: 0.6544\n",
      "Epoch 2/30\n"
     ]
    }
   ],
   "source": [
    "fittedModel = model.fit(X_train, y_train, batch_size = 100, epochs = 30, \n",
    "                        verbose = 2, validation_data=(X_test, y_test),\n",
    "                        class_weight = class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,7))\n",
    "plt.plot(model.history.history['val_acc'],label='val acc')\n",
    "#plt.plot(model.history.history['acc'],label=' acc')\n",
    "plt.plot(model.history.history['val_loss'],label='val loss')\n",
    "#plt.plot(model.history.history['loss'],label=' loss')\n",
    "# plt.plot(model.history.history['val_precision'],label='val_precision')\n",
    "# plt.plot(model.history.history['val_recall'],label='val_recall')\n",
    "plt.title('Accuracy and loss for learning rate 0.0001', fontsize=22)\n",
    "plt.xlabel('Number of epochs', fontsize=18)\n",
    "plt.ylabel('Accuracy',fontsize=18)\n",
    "plt.rc('xtick',labelsize=14)\n",
    "plt.rc('ytick',labelsize=14)\n",
    "plt.legend(fontsize=16)\n",
    "plt.legend(fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K \n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(model.history.history['val_acc']).mean(),np.array(model.history.history['val_loss']).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You are trying to load a weight file containing 14 layers into a model with 6 layers.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-473-9db4de72cfd9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'checkpoint.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprobs\u001b[0m       \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mpreds\u001b[0m       \u001b[1;33m=\u001b[0m \u001b[0mprobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0macc\u001b[0m         \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Classification accuracy: %f \"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0macc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\deep\\lib\\site-packages\\keras\\engine\\network.py\u001b[0m in \u001b[0;36mload_weights\u001b[1;34m(self, filepath, by_name, skip_mismatch, reshape)\u001b[0m\n\u001b[0;32m   1164\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1165\u001b[0m                 saving.load_weights_from_hdf5_group(\n\u001b[1;32m-> 1166\u001b[1;33m                     f, self.layers, reshape=reshape)\n\u001b[0m\u001b[0;32m   1167\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1168\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_updated_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\deep\\lib\\site-packages\\keras\\engine\\saving.py\u001b[0m in \u001b[0;36mload_weights_from_hdf5_group\u001b[1;34m(f, layers, reshape)\u001b[0m\n\u001b[0;32m   1028\u001b[0m                          \u001b[1;34m'containing '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1029\u001b[0m                          \u001b[1;34m' layers into a model with '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1030\u001b[1;33m                          str(len(filtered_layers)) + ' layers.')\n\u001b[0m\u001b[0;32m   1031\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1032\u001b[0m     \u001b[1;31m# We batch weight value assignments in a single backend call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: You are trying to load a weight file containing 14 layers into a model with 6 layers."
     ]
    }
   ],
   "source": [
    "# model.load_weights('checkpoint.h5')\n",
    "# probs       = model.predict(X_test)\n",
    "# preds       = probs.argmax(axis = -1)  \n",
    "# acc         = np.mean(preds == y_test.argmax(axis=-1))\n",
    "# print(\"Classification accuracy: %f \" % (acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 3\n",
    "# epochs = 200\n",
    "# model.fit(X_train, y_train,\n",
    "#           batch_size=batch_size,\n",
    "#           epochs=epochs,\n",
    "#           verbose=1,\n",
    "#           validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
